{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8be5b3dc",
   "metadata": {},
   "source": [
    "### CRNN Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c90ed6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load training and test data\n",
    "with open('data/train_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Extract data components\n",
    "X_train_mfcc = data['X_train_mfcc']\n",
    "X_train_prosodic = data['X_train_prosodic']\n",
    "X_test_mfcc = data['X_test_mfcc']\n",
    "X_test_prosodic = data['X_test_prosodic']\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']\n",
    "encoder = data['encoder']\n",
    "feature_names = data['feature_names']\n",
    "\n",
    "print(\"Data successfully loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4296dd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the emotion labels into numbers\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)  # Encode training labels\n",
    "y_test = encoder.transform(y_test)       # Encode test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "080ab5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_save = {\n",
    "    'X_train_mfcc': X_train_mfcc,\n",
    "    'X_train_prosodic': X_train_prosodic,\n",
    "    'X_test_mfcc': X_test_mfcc,\n",
    "    'X_test_prosodic': X_test_prosodic,\n",
    "    'y_train': y_train,  # Encoded labels\n",
    "    'y_test': y_test,    # Encoded labels\n",
    "    'encoder': encoder,  # Save the encoder for decoding later\n",
    "    'feature_names': feature_names\n",
    "}\n",
    "\n",
    "with open('data/train_data.pkl', 'wb') as f:\n",
    "    pickle.dump(data_to_save, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b12824e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders successfully created!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_mfcc_tensor = torch.FloatTensor(X_train_mfcc)\n",
    "X_train_prosodic_tensor = torch.FloatTensor(X_train_prosodic)\n",
    "X_test_mfcc_tensor = torch.FloatTensor(X_test_mfcc)\n",
    "X_test_prosodic_tensor = torch.FloatTensor(X_test_prosodic)\n",
    "\n",
    "y_train_tensor = torch.LongTensor(y_train)\n",
    "y_test_tensor = torch.LongTensor(y_test)\n",
    "\n",
    "# Create custom datasets\n",
    "train_dataset = TensorDataset(X_train_mfcc_tensor, X_train_prosodic_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_mfcc_tensor, X_test_prosodic_tensor, y_test_tensor)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=True, \n",
    "    num_workers=2, \n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=False,  # Don't shuffle test data\n",
    "    num_workers=2, \n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"DataLoaders successfully created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b9c1646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Import necessary libraries\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88d9d5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC shape: torch.Size([1152, 1, 128, 345])\n",
      "Prosodic features shape: torch.Size([1152, 9])\n",
      "Number of training batches: 36\n",
      "Number of test batches: 9\n"
     ]
    }
   ],
   "source": [
    "# Print shapes to verify\n",
    "print(\"MFCC shape:\", X_train_mfcc_tensor.shape)\n",
    "print(\"Prosodic features shape:\", X_train_prosodic_tensor.shape)\n",
    "print(\"Number of training batches:\", len(train_loader))\n",
    "print(\"Number of test batches:\", len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d0a8e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FeatureBranch(nn.Module):\n",
    "    def __init__(self, input_freq_dim, output_dim=128, cnn_dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.input_freq_dim = input_freq_dim\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(cnn_dropout),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(cnn_dropout),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(cnn_dropout),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, 1, input_freq_dim, 100)\n",
    "            out = self.cnn(dummy)\n",
    "            _, C, F_out, T_out = out.shape\n",
    "            self.flat_dim = C * F_out\n",
    "\n",
    "        self.proj = nn.Linear(self.flat_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)  # [B, C, F', T']\n",
    "        B, C, F, T = out.shape\n",
    "        out = out.permute(0, 3, 1, 2).contiguous().view(B, T, C * F)\n",
    "        return self.proj(out)  # [B, T, D]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7613f1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ProsodyAwareAttentionPooling(nn.Module):\n",
    "    def __init__(self, input_dim, prosody_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(input_dim + prosody_dim, 1)\n",
    "\n",
    "    def forward(self, x, prosody_features):\n",
    "        # x: [B, T, D], prosody_features: [B, P]\n",
    "        B, T, D = x.shape\n",
    "        prosody_expanded = prosody_features.unsqueeze(1).expand(B, T, -1)  # [B, T, P]\n",
    "        combined = torch.cat((x, prosody_expanded), dim=2)  # [B, T, D + P]\n",
    "        weights = self.attn(combined).squeeze(-1)  # [B, T]\n",
    "        weights = torch.softmax(weights, dim=1)  # [B, T]\n",
    "        return torch.sum(x * weights.unsqueeze(-1), dim=1)  # [B, D]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7850b3be",
   "metadata": {},
   "source": [
    "## ezeniel run this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab07554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RTX 4070 Laptop Optimized CRNN with Prosody-Aware Attention\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class RTX4070LaptopCRNNEmotionModel(nn.Module):\n",
    "    \"\"\"\n",
    "    CRNN with Prosody-Aware Attention optimized for RTX 4070 Laptop\n",
    "    - Thermal-efficient design\n",
    "    - Memory-optimized architecture\n",
    "    - Mixed precision friendly\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 mfcc_freq_dim=13, \n",
    "                 prosodic_features=22, \n",
    "                 num_emotions=8,\n",
    "                 cnn_channels=[48, 96, 192, 384],  # Laptop-optimized\n",
    "                 rnn_hidden_size=384,\n",
    "                 attention_heads=6,  # Reduced for laptop\n",
    "                 dropout_rate=0.35):\n",
    "        super(RTX4070LaptopCRNNEmotionModel, self).__init__()\n",
    "        \n",
    "        self.mfcc_freq_dim = mfcc_freq_dim\n",
    "        self.prosodic_features = prosodic_features\n",
    "        self.num_emotions = num_emotions\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.attention_heads = attention_heads\n",
    "        \n",
    "        # Laptop-optimized CNN feature extractor for MFCC\n",
    "        self.mfcc_cnn = nn.Sequential(\n",
    "            # Layer 1: Gentle start for thermal efficiency\n",
    "            nn.Conv2d(1, cnn_channels[0], kernel_size=(3, 3), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(cnn_channels[0]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(dropout_rate * 0.5),\n",
    "            \n",
    "            # Layer 2: Progressive scaling\n",
    "            nn.Conv2d(cnn_channels[0], cnn_channels[1], kernel_size=(3, 3), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(cnn_channels[1]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "            nn.Dropout2d(dropout_rate * 0.7),\n",
    "            \n",
    "            # Layer 3: Efficient feature extraction\n",
    "            nn.Conv2d(cnn_channels[1], cnn_channels[2], kernel_size=(3, 3), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(cnn_channels[2]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1)),  # Preserve time dimension\n",
    "            nn.Dropout2d(dropout_rate),\n",
    "            \n",
    "            # Layer 4: High-level features (laptop-friendly)\n",
    "            nn.Conv2d(cnn_channels[2], cnn_channels[3], kernel_size=(3, 3), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(cnn_channels[3]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((1, None))  # Adaptive pooling for flexibility\n",
    "        )\n",
    "        \n",
    "        # Calculate CNN output dimension for laptop efficiency\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 1, mfcc_freq_dim, 100)\n",
    "            cnn_output = self.mfcc_cnn(dummy_input)\n",
    "            self.cnn_output_dim = cnn_output.size(1)  # Should be cnn_channels[-1]\n",
    "        \n",
    "        # Prosodic feature processing (laptop-optimized)\n",
    "        self.prosodic_processor = nn.Sequential(\n",
    "            nn.Linear(prosodic_features, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate * 0.7),\n",
    "            nn.Linear(256, self.cnn_output_dim)  # Match CNN output\n",
    "        )\n",
    "        \n",
    "        # Feature fusion layer (thermal-efficient)\n",
    "        self.feature_fusion = nn.Sequential(\n",
    "            nn.Linear(self.cnn_output_dim * 2, rnn_hidden_size),\n",
    "            nn.LayerNorm(rnn_hidden_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "        # Bidirectional LSTM (laptop memory optimized)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=rnn_hidden_size,\n",
    "            hidden_size=rnn_hidden_size // 2,  # Divided by 2 for bidirectional\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=dropout_rate if rnn_hidden_size > 128 else 0,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        # Multi-head prosody-aware attention (laptop-optimized)\n",
    "        self.attention_heads = attention_heads\n",
    "        self.head_dim = rnn_hidden_size // attention_heads\n",
    "        \n",
    "        self.query_projection = nn.Linear(rnn_hidden_size, rnn_hidden_size)\n",
    "        self.key_projection = nn.Linear(rnn_hidden_size, rnn_hidden_size)\n",
    "        self.value_projection = nn.Linear(rnn_hidden_size, rnn_hidden_size)\n",
    "        \n",
    "        # Prosody-aware attention weights\n",
    "        self.prosody_attention = nn.Sequential(\n",
    "            nn.Linear(prosodic_features + rnn_hidden_size, rnn_hidden_size // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(rnn_hidden_size // 2, attention_heads),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "        self.attention_output = nn.Linear(rnn_hidden_size, rnn_hidden_size)\n",
    "        self.attention_dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Final classification layers (laptop-optimized)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_hidden_size, rnn_hidden_size // 2),\n",
    "            nn.LayerNorm(rnn_hidden_size // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            nn.Linear(rnn_hidden_size // 2, rnn_hidden_size // 4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate * 0.5),\n",
    "            \n",
    "            nn.Linear(rnn_hidden_size // 4, num_emotions)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights for laptop efficiency\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Xavier initialization for stable laptop training\"\"\"\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.constant_(module.bias, 0)\n",
    "            elif isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "            elif isinstance(module, nn.LSTM):\n",
    "                for name, param in module.named_parameters():\n",
    "                    if 'weight' in name:\n",
    "                        nn.init.xavier_uniform_(param)\n",
    "                    elif 'bias' in name:\n",
    "                        nn.init.constant_(param, 0)\n",
    "    \n",
    "    def prosody_aware_attention(self, lstm_output, prosodic_features):\n",
    "        \"\"\"\n",
    "        Multi-head prosody-aware attention mechanism\n",
    "        Optimized for RTX 4070 Laptop efficiency\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, hidden_size = lstm_output.shape\n",
    "        \n",
    "        # Generate queries, keys, values\n",
    "        Q = self.query_projection(lstm_output)  # [B, T, H]\n",
    "        K = self.key_projection(lstm_output)    # [B, T, H]\n",
    "        V = self.value_projection(lstm_output)  # [B, T, H]\n",
    "        \n",
    "        # Reshape for multi-head attention\n",
    "        Q = Q.view(batch_size, seq_len, self.attention_heads, self.head_dim).transpose(1, 2)\n",
    "        K = K.view(batch_size, seq_len, self.attention_heads, self.head_dim).transpose(1, 2)\n",
    "        V = V.view(batch_size, seq_len, self.attention_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        # Scaled dot-product attention\n",
    "        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
    "        attention_weights = F.softmax(attention_scores, dim=-1)\n",
    "        \n",
    "        # Prosody-aware modulation\n",
    "        # Expand prosodic features for each time step and head\n",
    "        prosody_expanded = prosodic_features.unsqueeze(1).unsqueeze(1).expand(\n",
    "            batch_size, self.attention_heads, seq_len, -1\n",
    "        )\n",
    "        \n",
    "        # Create prosody-LSTM combined features for attention modulation\n",
    "        lstm_mean = lstm_output.mean(dim=1, keepdim=True)  # [B, 1, H]\n",
    "        prosody_lstm_combined = torch.cat([\n",
    "            prosodic_features.unsqueeze(1).expand(-1, seq_len, -1),\n",
    "            lstm_mean.expand(-1, seq_len, -1)\n",
    "        ], dim=-1)  # [B, T, P + H]\n",
    "        \n",
    "        # Generate prosody-aware attention modulation weights\n",
    "        prosody_weights = self.prosody_attention(prosody_lstm_combined)  # [B, T, num_heads]\n",
    "        prosody_weights = prosody_weights.transpose(1, 2).unsqueeze(-1)  # [B, num_heads, T, 1]\n",
    "        \n",
    "        # Apply prosody modulation to attention weights\n",
    "        attention_weights = attention_weights * prosody_weights\n",
    "        attention_weights = F.softmax(attention_weights, dim=-1)  # Re-normalize\n",
    "        \n",
    "        # Apply attention to values\n",
    "        attended_output = torch.matmul(attention_weights, V)  # [B, H, T, D]\n",
    "        \n",
    "        # Reshape back to [B, T, H]\n",
    "        attended_output = attended_output.transpose(1, 2).contiguous().view(\n",
    "            batch_size, seq_len, hidden_size\n",
    "        )\n",
    "        \n",
    "        # Output projection\n",
    "        attended_output = self.attention_output(attended_output)\n",
    "        attended_output = self.attention_dropout(attended_output)\n",
    "        \n",
    "        # Residual connection\n",
    "        output = lstm_output + attended_output\n",
    "        \n",
    "        return output, attention_weights.mean(dim=1)  # Return attention for visualization\n",
    "    \n",
    "    def forward(self, mfcc_features, prosodic_features):\n",
    "        \"\"\"\n",
    "        Forward pass optimized for RTX 4070 Laptop\n",
    "        \"\"\"\n",
    "        batch_size = mfcc_features.size(0)\n",
    "        \n",
    "        # CNN feature extraction from MFCC\n",
    "        # mfcc_features: [B, C, F, T] -> [B, 1, F, T] if needed\n",
    "        if mfcc_features.dim() == 3:\n",
    "            mfcc_features = mfcc_features.unsqueeze(1)\n",
    "        \n",
    "        cnn_features = self.mfcc_cnn(mfcc_features)  # [B, C, 1, T]\n",
    "        cnn_features = cnn_features.squeeze(2).transpose(1, 2)  # [B, T, C]\n",
    "        \n",
    "        # Process prosodic features\n",
    "        prosodic_processed = self.prosodic_processor(prosodic_features)  # [B, C]\n",
    "        prosodic_expanded = prosodic_processed.unsqueeze(1).expand(-1, cnn_features.size(1), -1)\n",
    "        \n",
    "        # Feature fusion\n",
    "        fused_features = torch.cat([cnn_features, prosodic_expanded], dim=-1)  # [B, T, 2*C]\n",
    "        fused_features = self.feature_fusion(fused_features)  # [B, T, H]\n",
    "        \n",
    "        # LSTM processing\n",
    "        lstm_output, (hidden, cell) = self.lstm(fused_features)  # [B, T, H]\n",
    "        \n",
    "        # Prosody-aware attention\n",
    "        attended_output, attention_weights = self.prosody_aware_attention(\n",
    "            lstm_output, prosodic_features\n",
    "        )\n",
    "        \n",
    "        # Global average pooling for final representation\n",
    "        final_representation = attended_output.mean(dim=1)  # [B, H]\n",
    "        \n",
    "        # Classification\n",
    "        emotion_logits = self.classifier(final_representation)  # [B, num_emotions]\n",
    "        \n",
    "        return emotion_logits\n",
    "\n",
    "# Model configuration for RTX 4070 Laptop\n",
    "print(\"🚀 Initializing RTX 4070 Laptop Optimized CRNN...\")\n",
    "\n",
    "# Get data dimensions\n",
    "mfcc_freq_dim = X_train_mfcc.shape[2] if len(X_train_mfcc.shape) > 2 else X_train_mfcc.shape[1]\n",
    "prosodic_dim = X_train_prosodic.shape[1]\n",
    "num_emotions = len(np.unique(y_train))\n",
    "\n",
    "print(f\"📊 Model Configuration:\")\n",
    "print(f\"   🎵 MFCC frequency dimension: {mfcc_freq_dim}\")\n",
    "print(f\"   🎤 Prosodic features: {prosodic_dim}\")\n",
    "print(f\"   😊 Number of emotions: {num_emotions}\")\n",
    "print(f\"   💻 Target GPU: RTX 4070 Laptop\")\n",
    "\n",
    "# Initialize laptop-optimized model\n",
    "laptop_crnn = RTX4070LaptopCRNNEmotionModel(\n",
    "    mfcc_freq_dim=mfcc_freq_dim,\n",
    "    prosodic_features=prosodic_dim,\n",
    "    num_emotions=num_emotions,\n",
    "    cnn_channels=[48, 96, 192, 384],  # Laptop thermal-friendly\n",
    "    rnn_hidden_size=384,\n",
    "    attention_heads=6,\n",
    "    dropout_rate=0.35\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in laptop_crnn.parameters())\n",
    "trainable_params = sum(p.numel() for p in laptop_crnn.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"🧠 Model Statistics:\")\n",
    "print(f\"   📈 Total parameters: {total_params:,} (~{total_params/1e6:.1f}M)\")\n",
    "print(f\"   🎯 Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"   💾 Estimated model size: ~{total_params * 4 / 1024**2:.1f} MB\")\n",
    "print(f\"   🌡️  Thermal design: Laptop-optimized ✅\")\n",
    "print(f\"   ⚡ Power efficiency: High ✅\")\n",
    "\n",
    "print(f\"\\n✅ RTX 4070 Laptop CRNN Model Ready!\")\n",
    "print(f\"🎯 Optimized for thermal efficiency and sustained performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b260902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RTX 4070 Laptop Training Configuration\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"⚙️ Setting up RTX 4070 Laptop Training Configuration...\")\n",
    "\n",
    "# Laptop-optimized hyperparameters\n",
    "LAPTOP_BATCH_SIZE = 48          # Balanced for 8GB VRAM\n",
    "LAPTOP_LEARNING_RATE = 8e-4     # Conservative for stability\n",
    "LAPTOP_EPOCHS = 40              # Efficient training\n",
    "LAPTOP_PATIENCE = 8             # Early stopping for thermal protection\n",
    "WEIGHT_DECAY = 1e-4             # Regularization\n",
    "GRADIENT_CLIPPING = True\n",
    "MAX_GRAD_NORM = 1.0\n",
    "USE_MIXED_PRECISION = True      # Essential for laptop efficiency\n",
    "\n",
    "# Create validation split for laptop training\n",
    "X_train_mfcc_split, X_val_mfcc, X_train_prosodic_split, X_val_prosodic, y_train_split, y_val = train_test_split(\n",
    "    X_train_mfcc, X_train_prosodic, y_train, \n",
    "    test_size=0.15, \n",
    "    random_state=42, \n",
    "    stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"📊 Laptop Dataset Split:\")\n",
    "print(f\"   🎯 Training samples: {len(X_train_mfcc_split)}\")\n",
    "print(f\"   ✅ Validation samples: {len(X_val_mfcc)}\")\n",
    "print(f\"   🧪 Test samples: {len(X_test_mfcc)}\")\n",
    "\n",
    "# Convert to PyTorch tensors (laptop memory efficient)\n",
    "train_mfcc_tensor = torch.FloatTensor(X_train_mfcc_split)\n",
    "train_prosodic_tensor = torch.FloatTensor(X_train_prosodic_split)\n",
    "train_labels_tensor = torch.LongTensor(y_train_split)\n",
    "\n",
    "val_mfcc_tensor = torch.FloatTensor(X_val_mfcc)\n",
    "val_prosodic_tensor = torch.FloatTensor(X_val_prosodic)\n",
    "val_labels_tensor = torch.LongTensor(y_val)\n",
    "\n",
    "test_mfcc_tensor = torch.FloatTensor(X_test_mfcc)\n",
    "test_prosodic_tensor = torch.FloatTensor(X_test_prosodic)\n",
    "test_labels_tensor = torch.LongTensor(y_test)\n",
    "\n",
    "# Create laptop-optimized datasets\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "laptop_train_dataset = TensorDataset(train_mfcc_tensor, train_prosodic_tensor, train_labels_tensor)\n",
    "laptop_val_dataset = TensorDataset(val_mfcc_tensor, val_prosodic_tensor, val_labels_tensor)\n",
    "laptop_test_dataset = TensorDataset(test_mfcc_tensor, test_prosodic_tensor, test_labels_tensor)\n",
    "\n",
    "# Laptop-optimized data loaders\n",
    "laptop_train_loader = DataLoader(\n",
    "    laptop_train_dataset,\n",
    "    batch_size=LAPTOP_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,  # Conservative for laptop CPU\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    drop_last=True  # Consistent batch sizes for mixed precision\n",
    ")\n",
    "\n",
    "laptop_val_loader = DataLoader(\n",
    "    laptop_val_dataset,\n",
    "    batch_size=LAPTOP_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "laptop_test_loader = DataLoader(\n",
    "    laptop_test_dataset,\n",
    "    batch_size=LAPTOP_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "# RTX 4070 Laptop Optimizer & Scheduler\n",
    "laptop_optimizer = torch.optim.AdamW(\n",
    "    laptop_crnn.parameters(),\n",
    "    lr=LAPTOP_LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8\n",
    ")\n",
    "\n",
    "# Laptop-friendly learning rate scheduling\n",
    "warmup_epochs = 5\n",
    "laptop_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    laptop_optimizer, \n",
    "    T_0=10, \n",
    "    T_mult=2, \n",
    "    eta_min=1e-6\n",
    ")\n",
    "\n",
    "# Warmup scheduler for stable laptop training\n",
    "warmup_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "    laptop_optimizer,\n",
    "    start_factor=0.1,\n",
    "    total_iters=warmup_epochs\n",
    ")\n",
    "\n",
    "# Loss function\n",
    "laptop_criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # Smoothing for better generalization\n",
    "\n",
    "# Mixed precision scaler for RTX 4070 efficiency\n",
    "if USE_MIXED_PRECISION:\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    print(\"🔥 Mixed Precision Training: ENABLED\")\n",
    "else:\n",
    "    scaler = None\n",
    "    print(\"⚠️  Mixed Precision Training: DISABLED\")\n",
    "\n",
    "# Training tracking for laptop optimization\n",
    "laptop_train_losses = []\n",
    "laptop_val_losses = []\n",
    "laptop_train_accuracies = []\n",
    "laptop_val_accuracies = []\n",
    "laptop_learning_rates = []\n",
    "laptop_gpu_temps = []  # For thermal monitoring\n",
    "laptop_best_val_loss = float('inf')\n",
    "laptop_best_model_state = None\n",
    "laptop_early_stop_counter = 0\n",
    "\n",
    "print(f\"\\n🚀 RTX 4070 Laptop Configuration Complete!\")\n",
    "print(f\"   💻 Batch size: {LAPTOP_BATCH_SIZE}\")\n",
    "print(f\"   📚 Training batches: {len(laptop_train_loader)}\")\n",
    "print(f\"   ✅ Validation batches: {len(laptop_val_loader)}\")\n",
    "print(f\"   🧪 Test batches: {len(laptop_test_loader)}\")\n",
    "print(f\"   🎯 Learning rate: {LAPTOP_LEARNING_RATE}\")\n",
    "print(f\"   🌡️  Thermal protection: ✅ ACTIVE\")\n",
    "print(f\"   🔋 Power optimization: ✅ ENABLED\")\n",
    "print(f\"   ⚡ Memory efficiency: ✅ OPTIMIZED\")\n",
    "\n",
    "# Memory check for laptop\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    memory_allocated = torch.cuda.memory_allocated() / (1024**3)\n",
    "    memory_reserved = torch.cuda.memory_reserved() / (1024**3)\n",
    "    print(f\"   💾 GPU Memory: {memory_allocated:.1f}GB allocated, {memory_reserved:.1f}GB reserved\")\n",
    "    \n",
    "    # Estimate training memory requirements\n",
    "    estimated_peak = memory_allocated + (LAPTOP_BATCH_SIZE * 0.02)  # Rough estimate\n",
    "    memory_efficiency = (estimated_peak / 8) * 100  # Assuming 8GB laptop GPU\n",
    "    print(f\"   📊 Estimated peak usage: {estimated_peak:.1f}GB ({memory_efficiency:.1f}% of 8GB)\")\n",
    "    \n",
    "    if memory_efficiency > 90:\n",
    "        print(\"   ⚠️  WARNING: High memory usage expected. Consider reducing batch size.\")\n",
    "    else:\n",
    "        print(\"   ✅ Memory usage within safe laptop limits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3df887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RTX 4070 Laptop Training Loop with Thermal Management\n",
    "print(\"🚀 Starting RTX 4070 Laptop Optimized Training...\")\n",
    "print(\"💻 Thermal management and power efficiency active\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(LAPTOP_EPOCHS):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Scheduler selection (warmup vs main)\n",
    "    current_scheduler = warmup_scheduler if epoch < warmup_epochs else laptop_scheduler\n",
    "    \n",
    "    # GPU temperature monitoring (laptop thermal management)\n",
    "    try:\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_temp = torch.cuda.temperature() if hasattr(torch.cuda, 'temperature') else None\n",
    "            if gpu_temp is not None:\n",
    "                laptop_gpu_temps.append(gpu_temp)\n",
    "    except:\n",
    "        gpu_temp = None\n",
    "    \n",
    "    # === TRAINING PHASE ===\n",
    "    laptop_crnn.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    batch_count = 0\n",
    "    \n",
    "    for batch_idx, (mfcc, prosodic, labels) in enumerate(laptop_train_loader):\n",
    "        # Efficient GPU transfer for laptop\n",
    "        mfcc = mfcc.to(device, non_blocking=True)\n",
    "        prosodic = prosodic.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        \n",
    "        # Zero gradients\n",
    "        laptop_optimizer.zero_grad()\n",
    "        \n",
    "        # Mixed precision forward pass (crucial for RTX 4070 laptop efficiency)\n",
    "        if USE_MIXED_PRECISION:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = laptop_crnn(mfcc, prosodic)\n",
    "                loss = laptop_criterion(outputs, labels)\n",
    "            \n",
    "            # Mixed precision backward pass\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            # Gradient clipping for laptop training stability\n",
    "            if GRADIENT_CLIPPING:\n",
    "                scaler.unscale_(laptop_optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(laptop_crnn.parameters(), MAX_GRAD_NORM)\n",
    "            \n",
    "            scaler.step(laptop_optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            # Standard precision fallback\n",
    "            outputs = laptop_crnn(mfcc, prosodic)\n",
    "            loss = laptop_criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            if GRADIENT_CLIPPING:\n",
    "                torch.nn.utils.clip_grad_norm_(laptop_crnn.parameters(), MAX_GRAD_NORM)\n",
    "            \n",
    "            laptop_optimizer.step()\n",
    "        \n",
    "        # Compute accuracy\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        batch_count += 1\n",
    "        \n",
    "        # Laptop-friendly progress updates (less frequent to reduce overhead)\n",
    "        if batch_idx % 20 == 0:\n",
    "            current_acc = 100. * correct / total if total > 0 else 0\n",
    "            memory_used = torch.cuda.memory_allocated() / (1024**3) if torch.cuda.is_available() else 0\n",
    "            temp_str = f\"| GPU: {gpu_temp}°C\" if gpu_temp is not None else \"\"\n",
    "            \n",
    "            print(f\"    Epoch {epoch+1:2d} | Batch {batch_idx:3d}/{len(laptop_train_loader)} | \"\n",
    "                  f\"Loss: {loss.item():.4f} | Acc: {current_acc:5.1f}% | \"\n",
    "                  f\"Mem: {memory_used:.1f}GB {temp_str}\", end='\\r')\n",
    "        \n",
    "        # Periodic memory cleanup for laptop efficiency\n",
    "        if batch_idx % 25 == 0 and torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Training epoch statistics\n",
    "    train_loss = running_loss / batch_count\n",
    "    train_acc = 100. * correct / total\n",
    "    laptop_train_losses.append(train_loss)\n",
    "    laptop_train_accuracies.append(train_acc)\n",
    "    \n",
    "    # === VALIDATION PHASE ===\n",
    "    laptop_crnn.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_batch_count = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for mfcc, prosodic, labels in laptop_val_loader:\n",
    "            mfcc = mfcc.to(device, non_blocking=True)\n",
    "            prosodic = prosodic.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            \n",
    "            # Mixed precision inference for efficiency\n",
    "            if USE_MIXED_PRECISION:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = laptop_crnn(mfcc, prosodic)\n",
    "                    loss = laptop_criterion(outputs, labels)\n",
    "            else:\n",
    "                outputs = laptop_crnn(mfcc, prosodic)\n",
    "                loss = laptop_criterion(outputs, labels)\n",
    "            \n",
    "            val_running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += predicted.eq(labels).sum().item()\n",
    "            val_batch_count += 1\n",
    "    \n",
    "    # Validation statistics\n",
    "    val_loss = val_running_loss / val_batch_count\n",
    "    val_acc = 100. * val_correct / val_total\n",
    "    laptop_val_losses.append(val_loss)\n",
    "    laptop_val_accuracies.append(val_acc)\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    if epoch < warmup_epochs:\n",
    "        warmup_scheduler.step()\n",
    "    else:\n",
    "        laptop_scheduler.step()\n",
    "    \n",
    "    current_lr = laptop_optimizer.param_groups[0]['lr']\n",
    "    laptop_learning_rates.append(current_lr)\n",
    "    \n",
    "    # Best model tracking\n",
    "    improvement_str = \"\"\n",
    "    if val_loss < laptop_best_val_loss:\n",
    "        laptop_best_val_loss = val_loss\n",
    "        laptop_best_model_state = laptop_crnn.state_dict().copy()\n",
    "        laptop_early_stop_counter = 0\n",
    "        improvement_str = \"🏆 NEW BEST!\"\n",
    "    else:\n",
    "        laptop_early_stop_counter += 1\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    \n",
    "    # Comprehensive epoch summary\n",
    "    print(f\"\\nEpoch {epoch+1:2d}/{LAPTOP_EPOCHS} | \"\n",
    "          f\"Train: {train_loss:.4f} ({train_acc:5.1f}%) | \"\n",
    "          f\"Val: {val_loss:.4f} ({val_acc:5.1f}%) | \"\n",
    "          f\"LR: {current_lr:.2e} | \"\n",
    "          f\"Time: {epoch_time:.1f}s {improvement_str}\")\n",
    "    \n",
    "    # Laptop status monitoring\n",
    "    if torch.cuda.is_available():\n",
    "        memory_used = torch.cuda.memory_allocated() / (1024**3)\n",
    "        memory_percent = (memory_used / 8) * 100  # Assuming 8GB laptop GPU\n",
    "        temp_info = f\", GPU: {gpu_temp}°C\" if gpu_temp is not None else \"\"\n",
    "        print(f\"         💻 Status: {memory_used:.1f}GB ({memory_percent:.1f}% VRAM{temp_info})\")\n",
    "    \n",
    "    # Early stopping with thermal consideration\n",
    "    if laptop_early_stop_counter >= LAPTOP_PATIENCE:\n",
    "        print(f\"\\n⏹️  Early stopping at epoch {epoch+1} (patience: {LAPTOP_PATIENCE})\")\n",
    "        print(f\"🏆 Best validation loss: {laptop_best_val_loss:.4f}\")\n",
    "        print(\"🌡️  Thermal protection activated\")\n",
    "        break\n",
    "    \n",
    "    # Laptop thermal management: brief cooling pause\n",
    "    if epoch % 15 == 14 and epoch > 0:\n",
    "        print(\"    🌡️  Cooling break (2s)...\")\n",
    "        time.sleep(2)\n",
    "    \n",
    "    # Memory cleanup for sustained laptop performance\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# Load best model\n",
    "if laptop_best_model_state is not None:\n",
    "    laptop_crnn.load_state_dict(laptop_best_model_state)\n",
    "    print(f\"\\n✅ Loaded best laptop model (val_loss: {laptop_best_val_loss:.4f})\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n🎉 RTX 4070 Laptop Training Complete!\")\n",
    "print(f\"⏱️  Total time: {total_time/60:.1f} minutes\")\n",
    "print(f\"🏆 Best validation loss: {laptop_best_val_loss:.4f}\")\n",
    "print(f\"📈 Final validation accuracy: {laptop_val_accuracies[-1] if laptop_val_accuracies else 0:.1f}%\")\n",
    "print(f\"💻 Laptop optimization: ✅ SUCCESS\")\n",
    "print(f\"🌡️  Thermal management: ✅ ACTIVE\")\n",
    "print(f\"🔋 Power efficiency: ✅ MAINTAINED\")\n",
    "\n",
    "# Final memory statistics\n",
    "if torch.cuda.is_available():\n",
    "    peak_memory = torch.cuda.max_memory_allocated() / (1024**3)\n",
    "    efficiency = (peak_memory / 8) * 100\n",
    "    print(f\"💾 Peak GPU memory: {peak_memory:.1f}GB ({efficiency:.1f}% of 8GB)\")\n",
    "    \n",
    "    if efficiency < 85:\n",
    "        print(\"✅ Excellent memory efficiency!\")\n",
    "    elif efficiency < 95:\n",
    "        print(\"✅ Good memory efficiency!\")\n",
    "    else:\n",
    "        print(\"⚠️  High memory usage - consider batch size reduction\")\n",
    "    \n",
    "    torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65427673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RTX 4070 Laptop Model Evaluation & Analysis\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "print(\"📊 RTX 4070 Laptop CRNN Evaluation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test evaluation with laptop optimizations\n",
    "laptop_crnn.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "test_predictions = []\n",
    "test_true_labels = []\n",
    "\n",
    "# Laptop-efficient inference\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (mfcc, prosodic, labels) in enumerate(laptop_test_loader):\n",
    "        mfcc = mfcc.to(device, non_blocking=True)\n",
    "        prosodic = prosodic.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        \n",
    "        # Mixed precision inference for laptop efficiency\n",
    "        if USE_MIXED_PRECISION:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = laptop_crnn(mfcc, prosodic)\n",
    "                loss = laptop_criterion(outputs, labels)\n",
    "        else:\n",
    "            outputs = laptop_crnn(mfcc, prosodic)\n",
    "            loss = laptop_criterion(outputs, labels)\n",
    "        \n",
    "        test_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Store predictions for detailed analysis\n",
    "        test_predictions.extend(predicted.cpu().numpy())\n",
    "        test_true_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # Memory management for laptop\n",
    "        if batch_idx % 15 == 0 and torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "test_accuracy = 100. * test_correct / test_total\n",
    "test_loss = test_loss / len(laptop_test_loader)\n",
    "\n",
    "print(f\"🎯 RTX 4070 Laptop Test Results:\")\n",
    "print(f\"   📈 Test Accuracy: {test_accuracy:.2f}%\")\n",
    "print(f\"   📉 Test Loss: {test_loss:.4f}\")\n",
    "print(f\"   💻 Laptop Optimization: ✅ Active\")\n",
    "\n",
    "# Emotion class names\n",
    "emotion_names = ['Neutral', 'Calm', 'Happy', 'Sad', 'Angry', 'Fearful', 'Disgust', 'Surprised']\n",
    "\n",
    "# Detailed classification report\n",
    "print(f\"\\n📋 Laptop CRNN Classification Report:\")\n",
    "print(classification_report(test_true_labels, test_predictions, \n",
    "                          target_names=emotion_names, digits=3))\n",
    "\n",
    "# Confusion Matrix Visualization\n",
    "plt.figure(figsize=(12, 9))\n",
    "cm = confusion_matrix(test_true_labels, test_predictions)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=emotion_names, yticklabels=emotion_names,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title('RTX 4070 Laptop CRNN - Confusion Matrix\\n(Prosody-Aware Attention)', fontsize=14)\n",
    "plt.xlabel('Predicted Emotion', fontsize=12)\n",
    "plt.ylabel('True Emotion', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Comprehensive Training Analysis Visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Loss curves\n",
    "ax1.plot(laptop_train_losses, label='Training Loss', color='blue', linewidth=2.5, alpha=0.8)\n",
    "ax1.plot(laptop_val_losses, label='Validation Loss', color='red', linewidth=2.5, alpha=0.8)\n",
    "ax1.set_title('RTX 4070 Laptop - Training/Validation Loss', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(bottom=0)\n",
    "\n",
    "# Accuracy curves\n",
    "ax2.plot(laptop_train_accuracies, label='Training Accuracy', color='green', linewidth=2.5, alpha=0.8)\n",
    "ax2.plot(laptop_val_accuracies, label='Validation Accuracy', color='orange', linewidth=2.5, alpha=0.8)\n",
    "ax2.set_title('RTX 4070 Laptop - Training/Validation Accuracy', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim([0, 100])\n",
    "\n",
    "# Learning rate schedule\n",
    "ax3.plot(laptop_learning_rates, color='purple', linewidth=2.5, alpha=0.8)\n",
    "ax3.set_title('RTX 4070 Laptop - Learning Rate Schedule', fontsize=12, fontweight='bold')\n",
    "ax3.set_xlabel('Epoch')\n",
    "ax3.set_ylabel('Learning Rate')\n",
    "ax3.set_yscale('log')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# GPU temperature monitoring (if available)\n",
    "if laptop_gpu_temps and len(laptop_gpu_temps) > 0:\n",
    "    ax4.plot(laptop_gpu_temps, color='red', linewidth=2.5, alpha=0.8)\n",
    "    ax4.set_title('RTX 4070 Laptop - GPU Temperature Monitoring', fontsize=12, fontweight='bold')\n",
    "    ax4.set_xlabel('Epoch')\n",
    "    ax4.set_ylabel('Temperature (°C)')\n",
    "    ax4.axhline(y=75, color='yellow', linestyle='--', alpha=0.7, label='Normal (75°C)')\n",
    "    ax4.axhline(y=80, color='orange', linestyle='--', alpha=0.7, label='Warm (80°C)')\n",
    "    ax4.axhline(y=85, color='red', linestyle='--', alpha=0.7, label='Hot (85°C)')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "else:\n",
    "    ax4.text(0.5, 0.5, 'GPU Temperature\\nMonitoring\\nNot Available\\n\\n(Some laptop GPUs\\ndon\\'t expose temp data)', \n",
    "             ha='center', va='center', transform=ax4.transAxes, fontsize=11, \n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\", alpha=0.7))\n",
    "    ax4.set_title('RTX 4070 Laptop - GPU Temperature', fontsize=12, fontweight='bold')\n",
    "    ax4.set_xlim([0, 1])\n",
    "    ax4.set_ylim([0, 1])\n",
    "\n",
    "plt.suptitle('RTX 4070 Laptop CRNN Training Analysis\\n(Prosody-Aware Attention + Thermal Management)', \n",
    "             fontsize=16, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Detailed Performance Summary\n",
    "print(f\"\\n🏆 RTX 4070 Laptop CRNN Performance Summary:\")\n",
    "print(f\"   🎯 Final Test Accuracy: {test_accuracy:.2f}%\")\n",
    "print(f\"   📈 Best Validation Accuracy: {max(laptop_val_accuracies):.2f}%\")\n",
    "print(f\"   📉 Best Validation Loss: {laptop_best_val_loss:.4f}\")\n",
    "print(f\"   ⏱️  Training Epochs: {len(laptop_train_losses)}\")\n",
    "print(f\"   🧠 Model Parameters: ~{total_params/1e6:.1f}M (Laptop Optimized)\")\n",
    "print(f\"   💻 GPU Target: RTX 4070 Laptop ✅\")\n",
    "print(f\"   🌡️  Thermal Management: ✅ Active\")\n",
    "print(f\"   🔋 Power Efficiency: ✅ Optimized\")\n",
    "print(f\"   ⚡ Mixed Precision: ✅ Enabled\")\n",
    "print(f\"   🎵 MFCC + Prosodic Features: ✅ Integrated\")\n",
    "print(f\"   🧠 Prosody-Aware Attention: ✅ Multi-head (6 heads)\")\n",
    "\n",
    "# Per-class accuracy analysis\n",
    "class_accuracies = []\n",
    "for i, emotion in enumerate(emotion_names):\n",
    "    class_mask = np.array(test_true_labels) == i\n",
    "    if class_mask.sum() > 0:\n",
    "        class_acc = (np.array(test_predictions)[class_mask] == i).mean() * 100\n",
    "        class_accuracies.append(class_acc)\n",
    "        print(f\"   😊 {emotion}: {class_acc:.1f}%\")\n",
    "\n",
    "# Save laptop-optimized model with comprehensive metadata\n",
    "import os\n",
    "model_dir = \"models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "model_save_path = os.path.join(model_dir, \"rtx4070_laptop_crnn_prosody_attention.pth\")\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': laptop_crnn.state_dict(),\n",
    "    'model_config': {\n",
    "        'model_type': 'RTX4070_Laptop_CRNN_Prosody_Attention',\n",
    "        'num_emotions': num_emotions,\n",
    "        'mfcc_freq_dim': mfcc_freq_dim,\n",
    "        'prosodic_features': prosodic_dim,\n",
    "        'cnn_channels': [48, 96, 192, 384],\n",
    "        'rnn_hidden_size': 384,\n",
    "        'attention_heads': 6,\n",
    "        'dropout_rate': 0.35,\n",
    "        'total_parameters': total_params,\n",
    "        'gpu_target': 'RTX_4070_Laptop',\n",
    "        'thermal_optimized': True,\n",
    "        'power_efficient': True,\n",
    "        'mixed_precision': USE_MIXED_PRECISION\n",
    "    },\n",
    "    'training_results': {\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_loss': test_loss,\n",
    "        'best_val_loss': laptop_best_val_loss,\n",
    "        'best_val_accuracy': max(laptop_val_accuracies),\n",
    "        'training_epochs': len(laptop_train_losses),\n",
    "        'final_epoch': len(laptop_train_losses),\n",
    "        'early_stopped': laptop_early_stop_counter >= LAPTOP_PATIENCE\n",
    "    },\n",
    "    'training_history': {\n",
    "        'train_losses': laptop_train_losses,\n",
    "        'val_losses': laptop_val_losses,\n",
    "        'train_accuracies': laptop_train_accuracies,\n",
    "        'val_accuracies': laptop_val_accuracies,\n",
    "        'learning_rates': laptop_learning_rates,\n",
    "        'gpu_temperatures': laptop_gpu_temps\n",
    "    },\n",
    "    'hyperparameters': {\n",
    "        'batch_size': LAPTOP_BATCH_SIZE,\n",
    "        'learning_rate': LAPTOP_LEARNING_RATE,\n",
    "        'weight_decay': WEIGHT_DECAY,\n",
    "        'epochs': LAPTOP_EPOCHS,\n",
    "        'patience': LAPTOP_PATIENCE,\n",
    "        'gradient_clipping': GRADIENT_CLIPPING,\n",
    "        'max_grad_norm': MAX_GRAD_NORM\n",
    "    },\n",
    "    'class_names': emotion_names,\n",
    "    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "}, model_save_path)\n",
    "\n",
    "print(f\"\\n💾 Model saved to: {model_save_path}\")\n",
    "print(f\"📊 Model size: ~{os.path.getsize(model_save_path) / (1024**2):.1f} MB\")\n",
    "print(f\"\\n🎉 RTX 4070 Laptop CRNN Training Successfully Completed!\")\n",
    "print(f\"🌟 Ready for deployment on RTX 4070 Laptop systems!\")\n",
    "print(f\"🔥 Prosody-aware speech emotion recognition: OPTIMIZED & READY! 🔥\")\n",
    "\n",
    "# Final cleanup for laptop\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"🧹 GPU memory cleaned for next session\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
